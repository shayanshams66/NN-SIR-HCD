{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIRHCDQ(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SIRHCDQ, self).__init__()\n",
    "        self.t_inc = torch.Tensor([14.0]).double()#.cuda()\n",
    "        self.R_t = torch.Tensor([1.0]).double()#.cuda()\n",
    "        \n",
    "        self.t_hosp = nn.Parameter(9.5*torch.rand(1)+0.5,requires_grad=True) # (0.5, 10)\n",
    "        self.t_crit = nn.Parameter(18*torch.rand(1)+2,requires_grad=True) # (2, 20)\n",
    "        self.m_a = nn.Parameter(0.5*torch.rand(1)+0.5,requires_grad=True) # (0.5, 1)\n",
    "        self.c_a = nn.Parameter(torch.rand(1),requires_grad=True) # (0, 1)\n",
    "        self.f_a = nn.Parameter(torch.randn(1),requires_grad=True) #(0, 1)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(7, 10,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1,bias=True),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "    \n",
    "    def dS_dt(self, S, I, Q, R_t, t_inc):\n",
    "        return -((R_t + Q) / t_inc) * I * S\n",
    "\n",
    "\n",
    "    def dI_dt(self, S, I, Q, R_t, t_inc):\n",
    "        return ((R_t + Q) / t_inc) * I * S - (I / t_inc)\n",
    "    \n",
    "    \n",
    "    def dH_dt(self, I, C, H, t_inc, t_hosp, t_crit, m_a, f_a):\n",
    "        return ((1 - m_a) * (I / t_inc)) + ((1 - f_a) * C / t_crit) - (H / t_hosp)\n",
    "  \n",
    "\n",
    "    def dC_dt(self, H, C, t_hosp, t_crit, c_a):\n",
    "        return (c_a * H / t_hosp) - (C / t_crit)\n",
    "\n",
    "    \n",
    "    def dR_dt(self, I, H, t_inc, t_hosp, m_a, c_a):\n",
    "        return (m_a * I / t_inc) + (1 - c_a) * (H / t_hosp)\n",
    "\n",
    "    \n",
    "    def dD_dt(self, C, t_crit, f_a):\n",
    "        return f_a * C / t_crit\n",
    "\n",
    "    # Quarantined population equation\n",
    "    def dT_dt(self, I, Q):\n",
    "        return Q * I\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        S, I, R, H, C, D, T = y.double()\n",
    "        Q = self.net(y)\n",
    "        S_out = self.dS_dt(S, I, Q, self.R_t, self.t_inc)\n",
    "        I_out = self.dI_dt(S, I, Q, self.R_t, self.t_inc)\n",
    "        R_out = self.dR_dt(I, H, self.t_inc, self.t_hosp, self.m_a, self.c_a)\n",
    "        H_out = self.dH_dt(I, C, H, self.t_inc, self.t_hosp, self.t_crit, self.m_a, self.f_a)\n",
    "        C_out = self.dC_dt(H, C, self.t_hosp, self.t_crit, self.c_a)\n",
    "        D_out = self.dD_dt(C, self.t_crit, self.f_a)\n",
    "        T_out = self.dT_dt(I, Q)\n",
    "        results = torch.cat([S_out, I_out, R_out, H_out, C_out, D_out, T_out])\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/'\n",
    "output_path = 'data/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos_data_raw = pd.read_csv(train_path + 'Hopitalization_HOU.csv')\n",
    "hos_data_raw['Date'] = pd.to_datetime(hos_data_raw['Date'])\n",
    "hos_data_raw['Cum_Hosp'] = hos_data_raw['New_Hosp'].cumsum()\n",
    "hos_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "s = requests.get(url).content\n",
    "data_raw = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "data_raw = data_raw[data_raw['state']=='Texas']\n",
    "data_raw = data_raw.rename(columns={'date': 'Date', 'cases': 'ConfirmedCases', 'deaths': 'Fatalities'})\n",
    "data_raw['Date'] = pd.to_datetime(data_raw['Date'])\n",
    "\n",
    "data_raw = data_raw[data_raw['Date']<='2020-06-24']\n",
    "\n",
    "pop_info = pd.read_csv(train_path + 'covid_county_population_usafacts.csv')\n",
    "pop_info['County Name'] = pop_info['County Name'].apply(lambda x: ' '.join(x.split(' ')[:-1]))\n",
    "county_lookup = dict(zip(pop_info['County Name'], pop_info['population']))\n",
    "\n",
    "df = data_raw[['Date', 'county', 'ConfirmedCases', 'Fatalities']].reset_index()\n",
    "del df['index']\n",
    "\n",
    "\n",
    "pan_houston = [\"Harris\",\"Fort Bend\",\"Montgomery\",\"Brazoria\",\"Galveston\",\"Liberty\",\"Waller\",\"Chambers\",\"Austin\"]\n",
    "sum_fatalities_df = df[df['county'].isin(pan_houston)].groupby(['Date']).sum()\n",
    "\n",
    "sum_fatalities_df = sum_fatalities_df[sum_fatalities_df.index>=hos_data_raw['Date'].min()]\n",
    "hos_data_raw['Fatalities'] = list(sum_fatalities_df['Fatalities'])\n",
    "hos_data_raw['ConfirmedCases'] = list(sum_fatalities_df['ConfirmedCases'])\n",
    "hos_data_raw['county'] = 'Houston'\n",
    "\n",
    "hos_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for county in hos_data_raw['county'].unique():\n",
    "    hosp_list = hos_data_raw[hos_data_raw['county']==county]['Cum_Hosp'].rolling(window=7).mean().cummax()\n",
    "    fatalities_list = hos_data_raw[hos_data_raw['county']==county]['Fatalities'].rolling(window=7).mean().cummax()\n",
    "    hos_data_raw.loc[hos_data_raw['county']==county, 'Cum_Hosp'] = hosp_list\n",
    "    hos_data_raw.loc[hos_data_raw['county']==county, 'Fatalities'] = fatalities_list\n",
    "    hos_data_raw.loc[hos_data_raw['county']==county] = hos_data_raw.loc[hos_data_raw['county']==county].query('Cum_Hosp > 0')\n",
    "    \n",
    "hos_data_raw = hos_data_raw.dropna()\n",
    "hos_data_raw.set_index('Date', inplace=True)\n",
    "\n",
    "hos_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos_data_raw.iloc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_fun(vals):\n",
    "    x=vals.clone()\n",
    "    idx = x!=0\n",
    "    x[idx] = torch.log(x[idx])\n",
    "    return x\n",
    "\n",
    "def MSE_loss(pred, targets):\n",
    "    H_pred, D_pred = pred[:,2]+pred[:,3]+pred[:,4]+pred[:,5], pred[:,5]\n",
    "    H_true, D_true = targets[:,0], targets[:,1]\n",
    "    H_error_log = torch.pow(log_fun(H_pred) - log_fun(H_true),2)\n",
    "    D_error_log = torch.pow(log_fun(D_pred) - log_fun(D_true),2)\n",
    "    H_error = torch.pow(H_pred - H_true,2)\n",
    "    D_error = torch.pow(D_pred - D_true,2)\n",
    "    MSE = torch.mean(H_error + D_error)\n",
    "    MSLE = torch.mean(H_error_log+D_error_log)\n",
    "    ME = torch.mean(H_error + D_error)\n",
    "    return MSE,MSLE,ME\n",
    "\n",
    "def fit_model(train_full, area_name, predict_days=14, epochs=30000, make_plot=True):\n",
    "    data = train_full.copy()\n",
    "    best_cost=None\n",
    "    population = county_lookup[area_name]\n",
    "    n_deaths = data['Fatalities'].iloc[0]\n",
    "    n_recovered = 50\n",
    "    n_hosp = data['Cum_Hosp'].iloc[0] - n_recovered - n_deaths\n",
    "    n_crit = n_hosp * 0.05\n",
    "    n_hosp = n_hosp * 0.95\n",
    "    n_infected = n_hosp\n",
    "    n_quarantined = 10\n",
    "    n_susceptible = population - n_infected - n_deaths - n_recovered - n_hosp - n_crit\n",
    "    \n",
    "    initial_state = torch.tensor([n_susceptible, n_infected, n_recovered, n_hosp, n_crit, n_deaths, n_quarantined],dtype=torch.double) / population\n",
    "    initial_state=initial_state.to(device)\n",
    "    time_length_train = len(data) - predict_days\n",
    "    time_length_pre = len(data) + predict_days\n",
    "    times = torch.linspace(0., time_length_train, time_length_train).double().to(device)\n",
    "    times_pr = torch.linspace(0., time_length_pre, time_length_pre).double().to(device)\n",
    "    model = SIRHCDQ().double().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss = nn.MSELoss()\n",
    "    \n",
    "    for itr in range(1,epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        pred_y = odeint(model, initial_state,times,rtol=0.01)\n",
    "        y_true_cases = torch.stack([torch.tensor(data['Cum_Hosp'].values).double(), torch.tensor(data['Fatalities'].values).double()]).to(device)\n",
    "        y_true_cases = y_true_cases.permute(1,0)\n",
    "        pred_y = pred_y * population\n",
    "    \n",
    "        cost,logcost,ME = MSE_loss(pred_y[:time_length_train], y_true_cases[:time_length_train])\n",
    "        if best_cost is None:\n",
    "            best_cost = cost.data\n",
    "        else:\n",
    "            if logcost.data<best_cost:\n",
    "                best_cost=cost.data\n",
    "                torch.save(model.state_dict(), \"SIRHCDQ_2.th\")\n",
    "        \n",
    "        print(\"Iteration {:d} train MSE loss {:.6f} train MSLE loss {:.6f},train ME loss {:.6f}\".format(itr,cost,logcost,ME))\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % 20 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred_y = odeint(model, initial_state, times_pr,rtol=0.01)\n",
    "                pred_y = pred_y * population\n",
    "                \n",
    "                test_dates = list(data.index) + [pd.to_datetime(data.index.max()) + pd.DateOffset(i+1) for i in range(predict_days)]\n",
    "                pred_y_np = pred_y.cpu().numpy()\n",
    "                #test_data\n",
    "                test_data= pd.DataFrame({\n",
    "                    'Date': test_dates,\n",
    "                    'county': area_name,\n",
    "                    'Cum_Hosp': pred_y_np[:,2]+pred_y_np[:,3]+pred_y_np[:,4]+pred_y_np[:,5],\n",
    "                    'Fatalities':pred_y_np[:,5],\n",
    "                })\n",
    "                test_data.set_index('Date', inplace=True)\n",
    "                print(pred_y[time_length_train:].shape, y_true_cases[time_length_train:].shape)\n",
    "                cost_pr,logcost, ME = MSE_loss(pred_y[:len(data)], y_true_cases)\n",
    "                print(\"Iteration {:d} val MSE loss {:.6f} val MSLE loss {:.6f} val ME loss {:.6f}\".format(itr,cost_pr,logcost,ME))\n",
    " \n",
    "\n",
    "                fig, ((ax1, ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(10,10))    \n",
    "                ax1.set_title('Hopitalization')\n",
    "                ax2.set_title('Fatalities')\n",
    "                ax3.set_title('Hosptalization forecast')\n",
    "                ax4.set_title('Fatalities forecast')\n",
    "        #             plt.show(block=False)\n",
    "\n",
    "                data['Cum_Hosp'].plot(label='Hosptalization (train)', color='g', ax=ax1)\n",
    "                test_data.loc[data.index, 'Cum_Hosp'].plot(label='Modeled Cases', color='r', ax=ax1)\n",
    "\n",
    "                data['Fatalities'].plot(label='Fatalities (train)', color='g', ax=ax2)\n",
    "                test_data.loc[data.index, 'Fatalities'].plot(label='Modeled Fatalities', color='r', ax=ax2)\n",
    "\n",
    "                test_data[len(data):].loc[:, 'Cum_Hosp'].plot(label='Hosptalization(forecast)', color='r', linestyle=':', ax=ax3)\n",
    "                test_data[len(data):].loc[:, 'Fatalities'].plot(label='Fatalities (forecast)', color='g', linestyle=':', ax=ax4)\n",
    "\n",
    "                ax1.legend(loc='best')\n",
    "                ax2.legend(loc='best')\n",
    "                fig.tight_layout()\n",
    "                plt.draw()\n",
    "                plt.pause(0.001)\n",
    "            \n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "county = 'Houston'\n",
    "population = county_lookup[county]\n",
    "pr=fit_model(hos_data_raw, county)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
